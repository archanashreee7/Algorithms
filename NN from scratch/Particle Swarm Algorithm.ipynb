{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74e7ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100\n",
      "Iteration 2/100\n",
      "Iteration 3/100\n",
      "Iteration 4/100\n",
      "Iteration 5/100\n",
      "Iteration 6/100\n",
      "Iteration 7/100\n",
      "Iteration 8/100\n",
      "Iteration 9/100\n",
      "Iteration 10/100\n",
      "Iteration 11/100\n",
      "Iteration 12/100\n",
      "Iteration 13/100\n",
      "Iteration 14/100\n",
      "Iteration 15/100\n",
      "Iteration 16/100\n",
      "Iteration 17/100\n",
      "Iteration 18/100\n",
      "Iteration 19/100\n",
      "Iteration 20/100\n",
      "Iteration 21/100\n",
      "Iteration 22/100\n",
      "Iteration 23/100\n",
      "Iteration 24/100\n",
      "Iteration 25/100\n",
      "Iteration 26/100\n",
      "Iteration 27/100\n",
      "Iteration 28/100\n",
      "Iteration 29/100\n",
      "Iteration 30/100\n",
      "Iteration 31/100\n",
      "Iteration 32/100\n",
      "Iteration 33/100\n",
      "Iteration 34/100\n",
      "Iteration 35/100\n",
      "Iteration 36/100\n",
      "Iteration 37/100\n",
      "Iteration 38/100\n",
      "Iteration 39/100\n",
      "Iteration 40/100\n",
      "Iteration 41/100\n",
      "Iteration 42/100\n",
      "Iteration 43/100\n",
      "Iteration 44/100\n",
      "Iteration 45/100\n",
      "Iteration 46/100\n",
      "Iteration 47/100\n",
      "Iteration 48/100\n",
      "Iteration 49/100\n",
      "Iteration 50/100\n",
      "Iteration 51/100\n",
      "Iteration 52/100\n",
      "Iteration 53/100\n",
      "Iteration 54/100\n",
      "Iteration 55/100\n",
      "Iteration 56/100\n",
      "Iteration 57/100\n",
      "Iteration 58/100\n",
      "Iteration 59/100\n",
      "Iteration 60/100\n",
      "Iteration 61/100\n",
      "Iteration 62/100\n",
      "Iteration 63/100\n",
      "Iteration 64/100\n",
      "Iteration 65/100\n",
      "Iteration 66/100\n",
      "Iteration 67/100\n",
      "Iteration 68/100\n",
      "Iteration 69/100\n",
      "Iteration 70/100\n",
      "Iteration 71/100\n",
      "Iteration 72/100\n",
      "Iteration 73/100\n",
      "Iteration 74/100\n",
      "Iteration 75/100\n",
      "Iteration 76/100\n",
      "Iteration 77/100\n",
      "Iteration 78/100\n",
      "Iteration 79/100\n",
      "Iteration 80/100\n",
      "Iteration 81/100\n",
      "Iteration 82/100\n",
      "Iteration 83/100\n",
      "Iteration 84/100\n",
      "Iteration 85/100\n",
      "Iteration 86/100\n",
      "Iteration 87/100\n",
      "Iteration 88/100\n",
      "Iteration 89/100\n",
      "Iteration 90/100\n",
      "Iteration 91/100\n",
      "Iteration 92/100\n",
      "Iteration 93/100\n",
      "Iteration 94/100\n",
      "Iteration 95/100\n",
      "Iteration 96/100\n",
      "Iteration 97/100\n",
      "Iteration 98/100\n",
      "Iteration 99/100\n",
      "Iteration 100/100\n",
      "Predictions:\n",
      "[[0.96452047]\n",
      " [0.97708271]\n",
      " [0.980095  ]\n",
      " [0.98323748]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define the neural network class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
    "        self.bias_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
    "        self.bias_output = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward propagation\n",
    "        self.hidden_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "        self.output = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
    "        return sigmoid(self.output)\n",
    "\n",
    "    def mse_loss(self, predictions, targets):\n",
    "        return np.mean((targets - predictions) ** 2)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return np.concatenate([\n",
    "            self.weights_input_hidden.flatten(),\n",
    "            self.bias_hidden.flatten(),\n",
    "            self.weights_hidden_output.flatten(),\n",
    "            self.bias_output.flatten()\n",
    "        ])\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        input_hidden_end = self.weights_input_hidden.size\n",
    "        hidden_bias_end = input_hidden_end + self.bias_hidden.size\n",
    "        hidden_output_end = hidden_bias_end + self.weights_hidden_output.size\n",
    "\n",
    "        self.weights_input_hidden = parameters[:input_hidden_end].reshape(self.weights_input_hidden.shape)\n",
    "        self.bias_hidden = parameters[input_hidden_end:hidden_bias_end].reshape(self.bias_hidden.shape)\n",
    "        self.weights_hidden_output = parameters[hidden_bias_end:hidden_output_end].reshape(self.weights_hidden_output.shape)\n",
    "        self.bias_output = parameters[hidden_output_end:].reshape(self.bias_output.shape)\n",
    "\n",
    "# Define the Particle class\n",
    "class Particle:\n",
    "    def __init__(self, dimension):\n",
    "        self.position = np.random.rand(dimension)\n",
    "        self.velocity = np.random.rand(dimension)\n",
    "        self.best_position = self.position\n",
    "        self.best_fitness = float('-inf')\n",
    "\n",
    "# Define the Particle Swarm Optimization class\n",
    "class ParticleSwarmOptimization:\n",
    "    def __init__(self, population_size, inertia_weight, cognitive_coefficient, social_coefficient, max_iterations):\n",
    "        self.population_size = population_size\n",
    "        self.inertia_weight = inertia_weight\n",
    "        self.cognitive_coefficient = cognitive_coefficient\n",
    "        self.social_coefficient = social_coefficient\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def initialize_population(self, dimension):\n",
    "        return [Particle(dimension) for _ in range(self.population_size)]\n",
    "\n",
    "    def update_velocity(self, particle, global_best_position):\n",
    "        inertia_term = self.inertia_weight * particle.velocity\n",
    "        cognitive_term = self.cognitive_coefficient * np.random.rand() * (particle.best_position - particle.position)\n",
    "        social_term = self.social_coefficient * np.random.rand() * (global_best_position - particle.position)\n",
    "\n",
    "        new_velocity = inertia_term + cognitive_term + social_term\n",
    "        return new_velocity\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have input data `X` and target data `y`\n",
    "# Make sure to normalize your input data before training\n",
    "# (e.g., dividing by the maximum value or using z-score normalization)\n",
    "\n",
    "# Define input and target data\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 1\n",
    "chromosome_length = (input_size * hidden_size) + hidden_size + (hidden_size * output_size) + output_size\n",
    "\n",
    "# Create a neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Create a Particle Swarm Optimization algorithm\n",
    "population_size = 10\n",
    "inertia_weight = 0.5\n",
    "cognitive_coefficient = 2.0\n",
    "social_coefficient = 2.0\n",
    "max_iterations = 100\n",
    "\n",
    "pso = ParticleSwarmOptimization(population_size, inertia_weight, cognitive_coefficient, social_coefficient, max_iterations)\n",
    "\n",
    "# Initialize population\n",
    "particles = pso.initialize_population(chromosome_length)\n",
    "\n",
    "# Train the neural network using Particle Swarm Optimization\n",
    "for iteration in range(max_iterations):\n",
    "    print(f\"Iteration {iteration + 1}/{max_iterations}\")\n",
    "\n",
    "    for particle in particles:\n",
    "        nn.set_parameters(particle.position)\n",
    "        predictions = nn.forward(X)\n",
    "        fitness = 1 / nn.mse_loss(predictions, y)  # Fitness is inverse of MSE\n",
    "\n",
    "        if fitness > particle.best_fitness:\n",
    "            particle.best_fitness = fitness\n",
    "            particle.best_position = particle.position\n",
    "\n",
    "    global_best_particle = max(particles, key=lambda x: x.best_fitness).best_position\n",
    "\n",
    "    for particle in particles:\n",
    "        new_velocity = pso.update_velocity(particle, global_best_particle)\n",
    "        particle.velocity = new_velocity\n",
    "        particle.position += particle.velocity\n",
    "\n",
    "# Select the best individual from the final population\n",
    "best_particle = max(particles, key=lambda x: x.best_fitness)\n",
    "nn.set_parameters(best_particle.best_position)\n",
    "\n",
    "# Test the trained network\n",
    "predictions = nn.forward(X)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aced6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
